---
title: "MSDS-6371-Project Group 4"
author: "Ryan Herrin, Akib Hossain, Ronak Hamzehlou"
date: "4/6/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(plotly)
library(ggplot2)
library(plyr) # Load first before dplyer 
library(dplyr)
library(tidyr)
library(investr)
library(HH) 
library(scales)
library(olsrr)
```

Import Data
```{r}
house_train_loc <- "data/starting_data/train.csv"
house_test_loc <- "data/starting_data/test.csv"

# Read in data 
house_train <- read.csv(house_train_loc, header = TRUE)
house_test <- read.csv(house_test_loc, header = TRUE)
```

# Analysis Question 1
```{r}
# Create a data set that only includes the Neighborhoods, GrLIvArea, Salesprice
analys_1_data <- data.frame(Id=house_train$Id, Nbhd=house_train$Neighborhood,
                            GrLivArea=house_train$GrLivArea,
                            SalePrice=house_train$SalePrice)

# Narrow down the neighborhoods
analys_1_data <- filter(analys_1_data, 
                        Nbhd == "NAmes" | Nbhd == "Edwards" | Nbhd == "BrkSide")

# Create a scatter plot to visualize the initial data 
ggplot(analys_1_data, aes(x=GrLivArea, y=SalePrice, color=Nbhd)) +
  geom_point() + 
  scale_y_continuous(labels = unit_format(unit = "K", scale = 1e-3)) + 
  ggtitle("Sales Price vs Living Area (in sqft)")
```

- Edwards has a few outliers with high living areas space but a relatively average
Sale price. 
- Two noticable outliers in the Sales price 

```{r}
# find Edwards outliers from original data set
# aq_1 = analysis question 1
aq_1_grlivarea_outliers <- filter(analys_1_data, 
                                  Nbhd == "Edwards" & GrLivArea > 4000)
print(aq_1_grlivarea_outliers$Id)

# Find outliers for sales price
aq_1_price_outliers <- filter(analys_1_data, SalePrice > 3e+05)
print(aq_1_price_outliers$Id)
```

- This gives us ID 524, and 1299 for living area 
- And 643 and 725 for sale price 
- Need to keep an eye on the influence of these guys


Make seperate data frames for each Nhbd to reduce human errors from constantly 
filtering. Includes function to add or remove the outliers for the rest of the 
analysis 1 question. Always run this block before running lower blocks after 
a change is made. 
```{r}
# Create function that removes or adds back in the outliers if needed 

##############################################
# Set TRUE to include in data 
# Set FALSE to exclude from data 
use_price_outliers <- FALSE
use_grlivarea_outliers <- FALSE
##############################################

use_outlier <- function(data, bool_p, bool_la, p_outlrs, la_outlrs) {
  
  check_status <- function(data_tmp, x) {
    # Reusable to check if value is already in dataframe 
    if (x %in% data_tmp$Id) {return(TRUE)} else {return(FALSE)}
  }#END
  
  # Logic to add price outlier in data frame 
  if (bool_p == TRUE) {
    for (id in p_outlrs$Id) {
      if (check_status(data, id) == FALSE) {
        data = rbind(data, filter(p_outlrs, Id == id)) # Appends to df 
  }}}

  # Logic to remove price outlier in data frame 
  if (bool_p == FALSE) {
    for (id in p_outlrs$Id) {
      if (check_status(data, id) == TRUE) {
        data = data[!(data$Id == id),] # Remove from DF
  }}} 

  # Logic to add living area outlier in data frame 
  if (bool_la == TRUE) {
    for (id in la_outlrs$Id) {
      if (check_status(data, id) == FALSE) {
        data = rbind(data, filter(la_outlrs, Id == id)) # Appends to df 
  }}}

  # Logic to remove living area outlier in data frame 
  if (bool_la == FALSE) {
    for (id in la_outlrs$Id) {
      if (check_status(data, id) == TRUE) {
        data = data[!(data$Id == id),] # Remove from DF
  }}} 
  
  return(data) 
}

# Modifiy the dataframe to include or not include the outliers 
analys_1_data <- use_outlier(analys_1_data, use_price_outliers, 
                             use_grlivarea_outliers, aq_1_price_outliers,
                             aq_1_grlivarea_outliers)

# Make seperate data frames for each Nhbd
aq_1_NAmes <- filter(analys_1_data, Nbhd == "NAmes")
aq_1_Edwards <- filter(analys_1_data, Nbhd == "Edwards")
aq_1_BrkSide <- filter(analys_1_data, Nbhd == "BrkSide")

# Create fit models 
aq_1_NAmes_fit <- lm(SalePrice ~ GrLivArea, data=aq_1_NAmes)
aq_1_Edwards_fit <- lm(SalePrice ~ GrLivArea, data=aq_1_Edwards)
aq_1_BrkSide_fit <- lm(SalePrice ~ GrLivArea, data=aq_1_BrkSide)
aq_1_all_nbhd_fit <- lm(SalePrice ~ GrLivArea, data=analys_1_data)
```

Add charts and add linear regression lines
```{r}
# Create vars to set common scale for each plot
cust_y_lim <- c(50000, 350000)
cust_x_lim <- c(0, 6500)

# Linear regression plot for only NAmes
# Plot 
plot(aq_1_NAmes$GrLivArea, aq_1_NAmes$SalePrice, 
     xlab = "Living Area in sqft", ylab = "Sales Price in US Dollars",
     main= "NAmes with Regression", col = "blue", 
     xlim = cust_x_lim, ylim = cust_y_lim)
abline(aq_1_NAmes_fit, col = "blue") # Add regression line 

# Linear regression plot for only Edwards
# Plot 
plot(aq_1_Edwards$GrLivArea, aq_1_Edwards$SalePrice, 
     xlab = "Living Area in sqft", ylab = "Sales Price in US Dollars",
     main= "Edwards with Regression", col = "green", 
     xlim = cust_x_lim, ylim = cust_y_lim)
abline(aq_1_Edwards_fit, col = "green") # Add regression line 

# Linear regression plot for only BrkSide
# Plot 
plot(aq_1_BrkSide$GrLivArea, aq_1_BrkSide$SalePrice, 
     xlab = "Living Area in sqft", ylab = "Sales Price in US Dollars",
     main= "BrkSide with Regression", col = "red", 
     xlim = cust_x_lim, ylim = cust_y_lim)
abline(aq_1_BrkSide_fit, col = "red") # Add regression line 

# Create linear regression model with all locations included 
# Plot 
plot(analys_1_data$GrLivArea, analys_1_data$SalePrice, 
     xlab = "Living Area in sqft", ylab = "Sales Price in US Dollars",
     main = "All 3 Neighborhoods with Regression",
     xlim = cust_x_lim, ylim = cust_y_lim)
abline(aq_1_all_nbhd_fit) # Add regression line for combines
abline(aq_1_NAmes_fit, col = "blue")
abline(aq_1_Edwards_fit, col = "green")
abline(aq_1_BrkSide_fit, col = "red")
```

- There is vidual evidence that the slopes are different for each neighborhood

Print out a summary of each fit model 
```{r figures-side, out.width="50%"}
# Print Summary of fit models to find formula 
# NAmes
summary(aq_1_NAmes_fit)
plot(aq_1_NAmes_fit)

# Edwards
summary(aq_1_Edwards_fit)
plot(aq_1_Edwards_fit)

# BrkSide
summary(aq_1_BrkSide_fit)
plot(aq_1_BrkSide_fit)

# All 
summary(aq_1_all_nbhd_fit)
plot(aq_1_all_nbhd_fit)
```

## Model Formulas
```{r}
# Create Sales Price for NAmes
NAmes_int <- round(aq_1_NAmes_fit[["coefficients"]][["(Intercept)"]],digits=2)
NAmes_slope <- round(aq_1_NAmes_fit[["coefficients"]][["GrLivArea"]],digits=2)

# Create Sales Price for Edwards
Edwards_int <- round(aq_1_Edwards_fit[["coefficients"]][["(Intercept)"]],digits=2)
Edwards_slope <- round(aq_1_Edwards_fit[["coefficients"]][["GrLivArea"]],digits=2)

# Create Sales Price for BrkSide
BrkSide_int <- round(aq_1_BrkSide_fit[["coefficients"]][["(Intercept)"]],digits=2)
BrkSide_slope <- round(aq_1_BrkSide_fit[["coefficients"]][["GrLivArea"]],digits=2)

cat(
"(SalesPrice | NAmes) = ", NAmes_int, " + ", NAmes_slope, "(Sqft)\n",
"(SalesPrice | Edwards) = ", Edwards_int, " + ", Edwards_slope, "(Sqft)\n", 
"(SalesPrice | BrkSide) = ", BrkSide_int, " + ", BrkSide_slope, "(Sqft)\n",
sep = "")

# Create confidence Intervals for the slopes
# NAmes Upper 
NAmes_ci_upper <- aq_1_NAmes_fit[["coefficients"]][["GrLivArea"]] + 
  (qt(.975, (nrow(aq_1_NAmes)-2)) * summary(aq_1_NAmes_fit)$coefficients[2,2])
NAmes_ci_upper <- round(NAmes_ci_upper, digits = 2) # Round off 2 spots
# NAmes Lower 
NAmes_ci_lower <- aq_1_NAmes_fit[["coefficients"]][["GrLivArea"]] - 
  (qt(.975, (nrow(aq_1_NAmes)-2)) * summary(aq_1_NAmes_fit)$coefficients[2,2])
NAmes_ci_lower <- round(NAmes_ci_lower, digits = 2) # Round off 2 spots

# Edwards Upper  
Edwards_ci_upper <- aq_1_Edwards_fit[["coefficients"]][["GrLivArea"]] + 
  (qt(.975, (nrow(aq_1_Edwards)-2)) * summary(aq_1_Edwards_fit)$coefficients[2,2])
Edwards_ci_upper <- round(Edwards_ci_upper, digits = 2) # Round off 2 spots
# Edwards Lower 
Edwards_ci_lower <- aq_1_Edwards_fit[["coefficients"]][["GrLivArea"]] - 
  (qt(.975, (nrow(aq_1_Edwards)-2)) * summary(aq_1_Edwards_fit)$coefficients[2,2])
Edwards_ci_lower <- round(Edwards_ci_lower, digits = 2) # Round off 2 spots

# BrkSide Upper 
BrkSide_ci_upper <- aq_1_BrkSide_fit[["coefficients"]][["GrLivArea"]] + 
  (qt(.975, (nrow(aq_1_BrkSide)-2)) * summary(aq_1_BrkSide_fit)$coefficients[2,2])
BrkSide_ci_upper <- round(BrkSide_ci_upper, digits = 2) # Round off 2 spots
# BrkSide Lower 
BrkSide_ci_lower <- aq_1_BrkSide_fit[["coefficients"]][["GrLivArea"]] - 
  (qt(.975, (nrow(aq_1_BrkSide)-2)) * summary(aq_1_BrkSide_fit)$coefficients[2,2])
BrkSide_ci_lower <- round(BrkSide_ci_lower, digits = 2) # Round off 2 spots

# Print out confidence intervals 
cat(
'95% CI of NAmes [', NAmes_ci_lower, ', ', NAmes_ci_upper, ']\n', 
'95% CI of Edwards [', Edwards_ci_lower, ', ', Edwards_ci_upper, ']\n', 
'95% CI of BrkSide [', BrkSide_ci_lower, ', ', BrkSide_ci_upper, ']\n', 
sep = "")
```

# Analysis Question 2
```{r}
# Create a new DF that changes all chr columns into factors 
aq_2_house_train <- house_train

# Change "chr" columns into "factor" columns 
aq_2_house_train[sapply(aq_2_house_train, is.character)] <- 
  lapply(aq_2_house_train[sapply(aq_2_house_train, is.character)], as.factor)

# Change "int" columns into "numeric" columns
aq_2_house_train[sapply(aq_2_house_train, is.integer)] <- 
  lapply(aq_2_house_train[sapply(aq_2_house_train, is.integer)], as.numeric)

# Words cannot explain the pain it took to find out that these columns are the 
# ones causing the linear fit model to fail. 
aq_2_house_train <- subset(aq_2_house_train, 
                           select = -c(Street, Alley, Utilities, PoolQC, 
                                       MiscFeature, Condition2))

# Create Initial Model off original data set 
# Remove Id variable 
aq_2_init_model <- lm(SalePrice ~ . -Id, data = aq_2_house_train)
```

Okay lets narrow down the var selection by using the foward methed and setting
an initial P-value of .2 
```{r}
# Create the model to narrow down the selection
# Using the "olsrr" library
############################################################################
#ols_step_forward_p(aq_2_init_model, penter=0.2)
############################################################################
```

That took FOREVER to run.... I'm commenting it out so I don't have to run it again
Output is below:

                                Selection Summary                                 
---------------------------------------------------------------------------------
        Variable                       Adj.                                          
Step       Entered       R-Square    R-Square    C(p)       AIC           RMSE       
---------------------------------------------------------------------------------
   1    OverallQual        0.6257      0.6254     NaN    35659.4925    48622.7618    
   2    GrLivArea          0.7142      0.7138     NaN    35267.5843    42501.3029    
   3    Neighborhood       0.7868      0.7830     NaN    34887.2460    37008.5234    
   4    BsmtQual           0.8078      0.8038     NaN    33861.2011    35163.0890    
   5    RoofMatl           0.8269      0.8224     NaN    33726.7284    33459.8734    
   6    BsmtFinSF1         0.8477      0.8436     NaN    33546.4954    31395.8751    
   7    MSSubClass         0.8589      0.8550     NaN    33439.2811    30224.8066    
   8    BsmtExposure       0.8684      0.8645     NaN    33323.5880    29230.4864    
   9    KitchenQual        0.8768      0.8729     NaN    33235.6537    28311.5939    
  10    OverallCond        0.8814      0.8775     NaN    33184.3985    27796.4746    
  11    YearBuilt          0.8851      0.8813     NaN    33140.7575    27363.8972    
  12    LotArea            0.8885      0.8847     NaN    33100.3303    26968.5175    
  13    GarageCars         0.8906      0.8868     NaN    33075.2672    26722.8322    
  14    PoolArea           0.8924      0.8886     NaN    33053.5060    26510.1530    
  15    SaleCondition      0.8950      0.8908     NaN    33029.0629    26238.8848    
  16    TotalBsmtSF        0.8963      0.8922     NaN    33012.5543    26078.2183    
  17    Condition1         0.8986      0.8939     NaN    32996.8273    25864.7625    
  18    Fireplaces         0.8996      0.8949     NaN    32985.3270    25751.7579    
  19    ExterQual          0.9010      0.8961     NaN    32971.1178    25597.7283    
  20    Functional         0.9026      0.8974     NaN    32959.4450    25441.9764    
  21    LotConfig          0.9039      0.8984     NaN    32948.4802    25310.4650    
  22    Exterior1st        0.9063      0.9000     NaN    32938.4776    25113.8290    
  23    LandContour        0.9072      0.9007     NaN    32931.0707    25023.9359    
  24    BldgType           0.9082      0.9015     NaN    32923.1147    24921.4947    
  25    KitchenAbvGr       0.9086      0.9018     NaN    32919.5721    24882.3720    
  26    LowQualFinSF       0.9090      0.9022     NaN    32915.8277    24841.5542    
  27    YearRemodAdd       0.9093      0.9024     NaN    32912.5332    24804.7352    
  28    LandSlope          0.9098      0.9028     NaN    32908.8634    24756.6784    
  29    ScreenPorch        0.9101      0.9031     NaN    32905.9303    24723.1476    
  30    MSZoning           0.9108      0.9036     NaN    32902.6114    24662.3992    
  31    BedroomAbvGr       0.9111      0.9038     NaN    32899.5589    24627.9977    
  32    TotRmsAbvGrd       0.9116      0.9043     NaN    32893.6229    24568.7282    
  33    MasVnrArea         0.9117      0.9043     NaN    32704.8701    24523.6760    
  34    BsmtFullBath       0.9119      0.9044     NaN    32703.3935    24502.9508    
  35    GarageQual         0.9109      0.9026     NaN    31014.8491    24630.1265    
  36    GarageCond         0.9115      0.9029     NaN    31014.2780    24591.6965    
  37    WoodDeckSF         0.9117      0.9030     NaN    31013.3509    24574.9261    
  38    MoSold             0.9119      0.9031     NaN    31012.6265    24560.0329    
  39    X3SsnPorch         0.9120      0.9032     NaN    31012.4816    24550.4644    
  40    GarageFinish       0.9123      0.9033     NaN    31012.3148    24532.4900    
  41    MasVnrType         0.9126      0.9035     NaN    31013.1462    24515.5069    
  42    Foundation         0.9131      0.9036     NaN    31014.3962    24494.2920    
  43    LotFrontage        0.9177      0.9066     NaN    25468.2822    25412.9090    
  44    FullBath           0.9179      0.9067     NaN    25467.1392    25389.6561    
  45    LotShape           0.9184      0.9071     NaN    25466.0527    25347.1777    
  46    X1stFlrSF          0.9186      0.9071     NaN    25468.0752    25337.5077    
  47    X2ndFlrSF              NA          NA      NA            NA            NA    
---------------------------------------------------------------------------------

Alrighty. Lets create a new data set with only these guys 
```{r}
# Create a new DF with the VARs from the first forward run 
# Manually removing X1stFlrSF, X2ndFlrSF, and MoSold, RoofMatl, ScreenPorch
aq_2_train_reduced <- subset(aq_2_house_train, 
  select = c(Id, OverallQual, GrLivArea, Neighborhood, BsmtQual,  
             RoofMatl, BsmtFinSF1, MSSubClass, BsmtExposure, KitchenQual, 
             OverallCond, YearBuilt, LotArea, GarageCars, PoolArea, SaleCondition, 
             TotalBsmtSF, Condition1, Fireplaces, ExterQual, Functional, LotConfig, 
             LandContour, BldgType, KitchenAbvGr, LowQualFinSF, 
             YearRemodAdd, LandSlope, MSZoning, BedroomAbvGr, 
             TotRmsAbvGrd, MasVnrArea, BsmtFullBath, GarageQual, GarageCond, 
             WoodDeckSF, X3SsnPorch, GarageFinish, MasVnrType, Foundation,
             LotFrontage, FullBath, LotShape, SalePrice))
```

Split Data 80/20
```{r}
# Split the data 80/20 ##########
smp_size <- floor(0.80 * nrow(aq_2_train_reduced))
set.seed(123)
train_ind <- sample(seq_len(nrow(aq_2_train_reduced)), size = smp_size)
house_reduced_80 <- aq_2_train_reduced[train_ind, ]
house_reduced_20 <- aq_2_train_reduced[-train_ind, ]
#################################
```


```{r}
# Create another fit model
aq_2_reduced_model <- lm(SalePrice ~ . -Id, data = aq_2_train_reduced)
#summary(aq_2_reduced_model)
```


Now lets run that forward model again and see what it spits out 
```{r}
# Use another redection to create the forward model
aq_2_forward <- ols_step_forward_p(aq_2_reduced_model, penter = .05)
aq_2_reduced_fwd_model <- aq_2_forward$model
```

Try to predict with the forward model 
```{r}
# Makes a test to compare against the 80%
fwrd_results = data.frame(original=house_reduced_20$SalePrice,
                          est = predict(aq_2_reduced_fwd_model, house_reduced_20))
```

Okay, not bad. Let's create a kaggle output 
```{r}
fwrd_final <- data.frame(
  Id = house_test$Id,
  SalePrice = predict(aq_2_reduced_fwd_model, house_test)
)

write.csv(fwrd_final, "data/group4_Submission_fwd.csv", row.names = FALSE)
```

Kaggle Score of 0.18268

Backwards Model next
```{r}
# Create backwards model 
aq_2_back <- ols_step_backward_p(aq_2_reduced_model, prem = .07)
aq_2_reduced_model_back <- aq_2_back$model

#summary(aq_2_reduced_model_back)

# Test against test data 
back_results = data.frame(original=house_reduced_20$SalePrice,
                          est = predict(aq_2_reduced_model_back, 
                                        house_reduced_20))
```

It doesn't look as good as the frwd model

Create the stepwise model
```{r}
# Create a stepwise model
aq_2_step <- ols_step_both_p(aq_2_reduced_model, penter = 0.05, prem = .07)
aq_2_reduced_model_step <- aq_2_step$model

step_results = data.frame(original=house_reduced_20$SalePrice,
                          est = predict(aq_2_reduced_model_step, 
                                        house_reduced_20))
```

Create output for the actual results to submit to kaggle 
```{r}
step_final <- data.frame(
  Id = house_test$Id,
  SalePrice = predict(aq_2_reduced_model_step, house_test)
)

# Find and replace NA values
step_mean <- round(mean(step_final$SalePrice, na.rm = TRUE), digits = 2)
step_final$SalePrice[is.na(step_final$SalePrice)] <- step_mean

write.csv(step_final, "data/group4_Submission_step.csv", row.names = FALSE)
```
Kaggle Score: .20194